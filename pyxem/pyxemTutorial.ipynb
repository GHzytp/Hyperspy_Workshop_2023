{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-D STEM Analysis Using Pyxem \n",
    "\n",
    "\n",
    "## Data Inspection- Preprocessing - Unsupervised ML - Lazy Processing - Orientation Analysis \n",
    "\n",
    "\n",
    "### Carter Francis | University of Wisconsin Madison | May 24th 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyxem Introduction:\n",
    "-------------------\n",
    "\n",
    "`Pyxem` was first started in 2016 by Duncan Johnstone.  Since then it has been continually developed alongside hyperspy. Below is a very simplified dependancy tree for `pyxem`. We inherit quite a bit of functionality from upstream packages and ascribe strongly to the ideal that if we can upstream code to make it available to a wider audience we should!\n",
    "\n",
    "We are always looking for more people to join our team [here](https://github.com/pyxem/pyxem)!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img style=\"left\" src=\"imgs/DependancyTree.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Our Focus/ Goals:\n",
    "\n",
    "1. Provide Scalable analysis for pixelated(mostly 4-D STEM) diffraction \n",
    "    - Pyxem (and hyperspy) scales from single core --> Multi-core single machiene --> Multicore Distributed Computing!\n",
    "    - Fast I-O allows streaming and processing of TB sized datasets in under a ___minute___!\n",
    "    - Hyperspy is ___Fast___! I mean like really fast. If you don't believe me try running using the dask distributed backend. \n",
    "2. Provide End to End workflows without limiting functionality.\n",
    "    - A focus on documentation and example notebooks keeping the internal `pyxem` code simple and easy to maintain and grow.\n",
    "3. Testing Testing Testing!\n",
    "    - Pyxem is focused on test driven development which limits the number of bugs and helps us to understand why bugs arise when they do\n",
    "    - While not perfect this helps us to know that updates won't cause functionality to fail.\n",
    "4. Learning and Teaching!\n",
    "    - Drop by and say hi on github.  Make an [issue](https://github.com/pyxem/pyxem/issues) for a feature you would like, add some code you find helpful. \n",
    "    - Even if you are just trying something out or need help we are always happy to help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Introduction\n",
    "-----------------\n",
    "This data is a set of MgO nanocrystals on a lacy Carbon sample.  It is a pretty (very small) 4-D STEM dataset that I could load into RAM. But I personally still like to run everything lazily (and using the distributed backend) for a couple of reasons:\n",
    "\n",
    "1. I'm Lazy (why shouldn't my data be):\n",
    "    - I like things to load imediately and don't like waiting around\n",
    "    - Lazy makes things like running in parallel EASY\n",
    "2. Lazy means better parallelization (and it's Fast!):\n",
    "    - Lazy data is already set up to run in parallel so you get better control\n",
    "    - I love the dask-dashboard (and you should too)\n",
    "3. One workflow, Any Size of Data\n",
    "    - You can very easily take the same code. Move it to a cluster or a HPC cluster :)\n",
    "    - Lazy workflows mean faster iteration, faster discovery which means more experiments. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-D STEM (What is it?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img style=\"left\" src=\"imgs/4DSTEM.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contents\n",
    "<a id='Index'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. [Import pyxem and other required libraries](#Section0)\n",
    "1. [Loading and Inspection](#Section1)\n",
    "2. [Alignment & Calibration](#Section2)\n",
    "3. [Virtual Diffraction Imaging](#Section3)\n",
    "4. [Machine Learning SPED Data](#Section4)\n",
    "5. [Peak Finding and Segmentation](#Section5)\n",
    "6. [Orientation Mapping](#Section6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import pyxem and other required libraries\n",
    "<a id='Section0'></a>\n",
    "[To Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I like to print out the current version for hyperspy that I am using just in case I come back to a\n",
    "# notbook a many years later and things change slightly\n",
    "import hyperspy\n",
    "print(hyperspy.__version__)\n",
    "import pyxem\n",
    "print(pyxem.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the matplotlib background will give you interactive \n",
    "%matplotlib qt5\n",
    "#%matplotlib inline\n",
    "#%matplotlib widget # for plotting when running remotely on a cluster etc.\n",
    "import hyperspy.api as hs\n",
    "import pyxem as pxm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting up a distributed Cluster locally \n",
    "# You don't have to do this but it helps to visualize what is happening\n",
    "from dask.distributed import Client\n",
    "client = Client()  # set up local cluster on your laptop\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loa'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Loading and Inspection\n",
    "<a id='Section1'></a>\n",
    "[To Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SPED data acquired from the nano-crystals using hyperspy.\n",
    "\n",
    "`Note: Because pyxem extends hyperspy this happens automatically!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperspy.api as hs\n",
    "dp = hs.load(\"data/mgo_nanoparticles.zspy\", lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets just look at the data \n",
    "# display(dp) also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets change the title here so it shows up when we load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Then we can display the data strucuture again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the dp object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently the navigator isn't set so in order to plot this we have to \"create\" one by\n",
    "# summing the entire dataset. Look at the distributed task-stream to see all of the chunks are\n",
    "# loaded and then a Summed navigator is created.  This isn't very efficient (or lazy!)\n",
    "\n",
    "\n",
    "# if you rerun this cell the navigator is saved (Yay) and it takes much less time to plot the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data type of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the metadata associated with the object 'dp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set important experimental parameters using the built in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.set_experimental_parameters(beam_energy=300.0,\n",
    "                               camera_length=21.0,\n",
    "                               scan_rotation=277.0,\n",
    "                               convergence_angle=0.7,\n",
    "                               exposure_time=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how this changed the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data to inspect it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Alignment & Calibration\n",
    "<a id='Section2'></a>\n",
    "[To Index](#Index)\n",
    "\n",
    "Let's center the direct beam for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the direct beam position using `get_direct_beam_position`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the shifts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the orginal shifts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make the shifts into a linear plane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the shifts again!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align the dataset based on the direct beam position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the Calibration\n",
    "Set the calibration. This is usually known for some detector from a standard sample\n",
    "or you can get this from the dataset if the scale is known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scale = 0.03246\n",
    "scale_real = 3.03\n",
    "dp.set_diffraction_calibration(scale)\n",
    "dp.set_scan_calibration(scale_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot calibrated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vdf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Virtual Diffraction Imaging & Selecting Regions\n",
    "<a id='Section3'></a>\n",
    "[To Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Interactive VDF Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an interactive virtual image integrating intensity within a circular subset of pixels in the diffraction pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the rois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coompute the mean dp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets just add a custom VDF to the image to get both VDF and VBF images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inspect the bf roi I like to save these values above for reproduceability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add df roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inspect the Df roi I like to save these values above for reproduceability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the integrated intensity for the bf and df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the virtual diffraction image associated with the last integration window used interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot both virtual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Azimuthal Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyxem uses the [`pyfai`](https://github.com/silx-kit/pyFAI/tree/v2023.1) library to handle azimuthal integrations including the effects of the Ewald Sphere.  Because of this you should set the calibration and the beam energy before integration.\n",
    "\n",
    "For speed a AzimuthalIntegrator object is precomputed which reduces redundant calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the unit and beam_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the Azimuthal Integrator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the 1D Azimuthal Integration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the inverse to get the VDF as a function of radius \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Select a region in the scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data with an adjustable marker indicating where to crop the scan region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = hs.roi.RectangularROI(left=50.,\n",
    "                            top=100.,\n",
    "                            right=100.,\n",
    "                            bottom=300.)\n",
    "dp.plot(cmap='inferno')\n",
    "reg.add_widget(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean from the selected area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Unsupervised learning\n",
    "<a id='Section4'></a>\n",
    "[To Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform singular value decomposition (SVD) of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain a \"Scree plot\" by plotting the fraction of variance described by each principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SVD won't converage with zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lazy decompositions only work with the processes and threaded schedulers (not the distributed scheduler)\n",
    "dpc.compute() # compute this to load it into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform a SVD Decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_explained_variance_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform NNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot decomposition results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vec'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Peak Finding\n",
    "<a id='Section5'></a>\n",
    "[To Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform peak finding on all diffraction patterns in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find peaks in the 2D dataset\n",
    "# This will immediately compute and return a BaseSignal\n",
    "peaks = dp.find_peaks(method='difference_of_gaussian',\n",
    "                       min_sigma=1.,\n",
    "                       max_sigma=6.,\n",
    "                       sigma_ratio=1.6,\n",
    "                       threshold=0.04,\n",
    "                       overlap=0.99,\n",
    "                       interactive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the peaks object type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyxem.signals import DiffractionVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the peaks found to a Diffraction Vectors Object\n",
    "dv = DiffractionVectors.from_peaks(peaks, center=(72, 72), calibration=dp.axes_manager.signal_axes[0].scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at what's in the peaks object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of peaks found at each point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cluster the vectors\n",
    "distance_threshold = 0.1\n",
    "min_samples = 7\n",
    "unique_peaks = dv.get_unique_vectors(method='DBSCAN',\n",
    "                                     distance_threshold=distance_threshold,\n",
    "                                     min_samples=min_samples)\n",
    "print(np.shape(unique_peaks.data)[0], ' unique vectors were found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove the zero beam\n",
    "unique_peaks = unique_peaks.filter_magnitude(min_magnitude=.4,\n",
    "                                   max_magnitude=np.inf)\n",
    "print(np.shape(unique_peaks)[0], ' unique vectors.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the transpose and the unique vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create Virtual Images from the unique vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compute the Virtual darkfield images from the peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_distance = 10.5\n",
    "min_size = 40\n",
    "max_size = 1000\n",
    "max_number_of_grains = 3000\n",
    "marker_radius = 2\n",
    "exclude_border = 2\n",
    "threshold= 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test for the right watershed parameters\n",
    "from pyxem.utils.segment_utils import separate_watershed\n",
    "i = 21\n",
    "sep_i = separate_watershed(\n",
    "    VDFs.inav[i].data, min_distance=min_distance, min_size=min_size,\n",
    "    max_size=max_size, max_number_of_grains=max_number_of_grains,\n",
    "    exclude_border=exclude_border, marker_radius=marker_radius,\n",
    "    threshold=threshold, plot_on=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get VDF segments\n",
    "segs = VDFs.get_vdf_segments(min_distance=min_distance,\n",
    "                             min_size=min_size,\n",
    "                             max_size = max_size,\n",
    "                             max_number_of_grains = max_number_of_grains,\n",
    "                             exclude_border=exclude_border,\n",
    "                             marker_radius=marker_radius,\n",
    "                             threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate normalised cross-correlations between all VDF image segments to identify those that are related to the same crystal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get cross correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the correlation value exceeds corr_threshold for certain segments, those segments are summed. These segments are discarded if the number of these segments are below vector_threshold, as this number corresponds to the number of detected diffraction peaks associated with the single crystal. The vector_threshold criteria is included to avoid including segment images resulting from noise or incorrect segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_threshold=0.3\n",
    "vector_threshold=4\n",
    "segment_threshold=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrsegs = segs.correlate_vdf_segments(\n",
    "    corr_threshold=corr_threshold, vector_threshold=vector_threshold,\n",
    "    segment_threshold=segment_threshold)\n",
    "print(np.shape(corrsegs.segments)[0],' correlated segments were found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot correlation segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Orientation Mapping\n",
    "<a id='Section6'></a>\n",
    "[To Index](#Index)\n",
    "\n",
    "Another way we can look at the different crystals is using orientation mapping.  In this case we take the known crystal strucuture and then compute the kinematic diffraction patterns.  Then we cross correlate each pattern with each diffraction pattern and return the pattern which matches most closely. \n",
    "\n",
    "Currently, the algorithm doesn't take into account crystals in projection but that is something that we could add (Or you could add if you are interested!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a slice of that data\n",
    "dp_slic = dp.inav[10:50,30:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the background using Difference of Gaussians\n",
    "dp_slic = dp_slic.subtract_diffraction_background(method=\"difference of gaussians\",\n",
    "                                                  min_sigma=2.5,\n",
    "                                                  max_sigma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the subtacted image. \n",
    "#dp_slic.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import diffpy and diffsims for loading and simulating data\n",
    "import diffpy\n",
    "from diffsims.libraries.structure_library import StructureLibrary\n",
    "from diffsims.generators.diffraction_generator import DiffractionGenerator\n",
    "from diffsims.generators.library_generator import DiffractionLibraryGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a grid of roatations\n",
    "from diffsims.generators.rotation_list_generators import get_beam_directions_grid\n",
    "resolution = 1.5 # maximum angle in degrees between nearest templates. Pretty rough grid for speed.\n",
    "grid_cub = get_beam_directions_grid(\"hexagonal\", resolution, mesh=\"spherified_cube_edge\")\n",
    "print(\"Number of patterns: \", grid_cub.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters necessary for simulating a template library\n",
    "# half size of the images\n",
    "diffraction_calibration=dp.axes_manager.signal_axes[0].scale\n",
    "half_shape = (dp.data.shape[-2]//2, dp.data.shape[-1]//2)\n",
    "# maximum radius in reciprocal space to calculate spot intensities for\n",
    "reciprocal_radius = np.sqrt(half_shape[0]**2 + half_shape[1]**2)*diffraction_calibration\n",
    "print(\"Max Recip. Radius: \", reciprocal_radius, \"Inverse Angstroms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simulate the diffraction patterns for MgO\n",
    "structure_matrix = diffpy.structure.loadStructure(\"data/MgO.cif\")\n",
    "\n",
    "# \"The microscope = the parameters that determine how the templates are calculated\"\n",
    "diff_gen = DiffractionGenerator(accelerating_voltage=300,\n",
    "                                precession_angle=0,\n",
    "                                scattering_params=None,\n",
    "                                shape_factor_model=\"linear\",\n",
    "                                minimum_intensity=0.1,\n",
    "                                )\n",
    "\n",
    "lib_gen = DiffractionLibraryGenerator(diff_gen)\n",
    "\n",
    "# Generating a library\n",
    "# \"Library of structures and orientations\"\n",
    "library_phases_mgo = StructureLibrary([\"MgO\"], [structure_matrix], [grid_cub])\n",
    "# Calculate the actual library\n",
    "\n",
    "diff_lib_mgo = lib_gen.get_diffraction_library(library_phases_mgo,\n",
    "                                              calibration=diffraction_calibration,\n",
    "                                              reciprocal_radius=2,\n",
    "                                              half_shape=half_shape,\n",
    "                                              with_direct_beam=False,\n",
    "                                              max_excitation_error=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyxem.utils import indexation_utils as iutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delta_r = 2 # spacing in r (in pixels)\n",
    "delta_theta = 1 # spacings in theta (in degrees)\n",
    "max_r = None # max radius to consider\n",
    "intensity_transform_function = None # transform the intensity with a function\n",
    "find_direct_beam = False  # convenience, if the pattern was not centered, this will perform a rough centering\n",
    "direct_beam_position = (72,72) # direct beam position (centered in pixels)\n",
    "normalize_image = True # divide the correlation by the norm of the image\n",
    "normalize_templates = True  # divide the correlation by the norm of the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frac_keep = 0.8 \n",
    "n_keep = None\n",
    "\n",
    "# if frac_keep < 1 or 1 < n_keep < number of templates then indexation\n",
    "# templates in \"indexes\" that have the highest \"fast\" correlation\n",
    "n_best = 5 # keep the 5 best rotations\n",
    "result, phasedict = iutls.index_dataset_with_template_rotation(dp_slic,\n",
    "                                                    diff_lib_mgo,\n",
    "                                                    phases = [\"MgO\"],  # if we have multiple phases we can also specify which ones we want to consider. If it's not specified, all phases are used.\n",
    "                                                    n_best = n_best,\n",
    "                                                    frac_keep = frac_keep,\n",
    "                                                    n_keep = n_keep,\n",
    "                                                    delta_r = delta_r,\n",
    "                                                    delta_theta = delta_theta,\n",
    "                                                    max_r = 50,\n",
    "                                                    intensity_transform_function=intensity_transform_function,\n",
    "                                                    normalize_images = normalize_image,\n",
    "                                                    normalize_templates=normalize_templates,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plotting the orientation maps and the Inverse Pole Figures\n",
    "solution = result[\"orientation\"]\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from orix.projections import StereographicProjection\n",
    "\n",
    "# map a vector onto the fundamental zone of the hexagon\n",
    "def to_fundamental(data_sol):\n",
    "    data_sol = np.abs(data_sol)\n",
    "    data_sol = np.sort(data_sol, axis=-1)\n",
    "    column = data_sol[...,0].copy()\n",
    "    data_sol[..., 0] = data_sol[...,1]\n",
    "    data_sol[..., 1] = column\n",
    "    return data_sol\n",
    "\n",
    "\n",
    "def get_ipf_color(vectors):\n",
    "    # the following column vectors should map onto R [100], G [010], B[001], i.e. the identity. So the inverse of \n",
    "    # this matrix maps the beam directions onto the right color vector\n",
    "    color_corners = np.array([[0, 1, 1],\n",
    "                              [0, 0, 1],\n",
    "                              [1, 1, 1]])\n",
    "    color_mapper = np.linalg.inv(color_corners)\n",
    "    # a bit of wrangling\n",
    "    data_sol = to_fundamental(vectors.data)\n",
    "    flattened = data_sol.reshape(np.product(data_sol.shape[:-1]), 3).T\n",
    "    rgb_mapped = np.dot(color_mapper, flattened)\n",
    "    rgb_mapped = np.abs(rgb_mapped / rgb_mapped.max(axis=0)).T\n",
    "    rgb_mapped = rgb_mapped.reshape(data_sol.shape)\n",
    "    return rgb_mapped\n",
    "    \n",
    "    \n",
    "from orix.quaternion.rotation import Rotation\n",
    "from orix.vector.vector3d import Vector3d\n",
    "\n",
    "# draw IPF - Z (row 1), IPF - Y (row 2), IPF - Z (row 3)\n",
    "fig, ax = plt.subplots(ncols = solution.shape[2], nrows = 3, figsize = (10, 6))\n",
    "\n",
    "for i in range(solution.shape[2]):\n",
    "    solution_vectors_z = Rotation.from_euler(np.deg2rad(solution[:,:,i,:]))*Vector3d.zvector()    \n",
    "    solution_vectors_y = Rotation.from_euler(np.deg2rad(solution[:,:,i,:]))*Vector3d.yvector()    \n",
    "    solution_vectors_x = Rotation.from_euler(np.deg2rad(solution[:,:,i,:]))*Vector3d.xvector()    \n",
    "    ax[0, i].set_title(f\"Solution {i}\")\n",
    "    ax[0, i].imshow(get_ipf_color(solution_vectors_z))\n",
    "    ax[1, i].imshow(get_ipf_color(solution_vectors_y))\n",
    "    ax[2, i].imshow(get_ipf_color(solution_vectors_x))\n",
    "\n",
    "ax[0,0].set_ylabel(\"IPF-Z\")\n",
    "ax[1,0].set_ylabel(\"IPF-Y\")\n",
    "ax[2,0].set_ylabel(\"IPF-X\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:hyperspy-bundle] *",
   "language": "python",
   "name": "conda-env-hyperspy-bundle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "state": {
    "129b93d3ba954eb992d51fbf1e9b155e": {
     "views": [
      {
       "cell_index": 57
      }
     ]
    },
    "2ab3842519c3455592db5c834d2e33d8": {
     "views": [
      {
       "cell_index": 57
      }
     ]
    },
    "4033f1e346fd446bb8112a0ab4c1852d": {
     "views": [
      {
       "cell_index": 57
      }
     ]
    },
    "4316c6dbe2df4359be7a8af660609743": {
     "views": [
      {
       "cell_index": 61
      }
     ]
    },
    "449d4a42101d4fc79c6b6203b974695a": {
     "views": [
      {
       "cell_index": 59
      }
     ]
    },
    "48c6dfcccf1840baa54fa734f34c8f51": {
     "views": [
      {
       "cell_index": 57
      }
     ]
    },
    "5bf055ba0910450084cb44f31ff8a2eb": {
     "views": [
      {
       "cell_index": 61
      }
     ]
    },
    "bcb00cf357ee479ba389e9d19aa21bc5": {
     "views": [
      {
       "cell_index": 61
      }
     ]
    },
    "c2b0145b674c42988487114076efc891": {
     "views": [
      {
       "cell_index": 57
      }
     ]
    },
    "c77915d7befa4215a8ca901c6f8a82e5": {
     "views": [
      {
       "cell_index": 57
      }
     ]
    },
    "da3f026a56564b6195cb500d77e5e13a": {
     "views": [
      {
       "cell_index": 63
      }
     ]
    },
    "dfc7d3578ffb4ab79dc72e22be3f6255": {
     "views": [
      {
       "cell_index": 63
      }
     ]
    },
    "fb5ae80c36384f049ed13c49801cd8f6": {
     "views": [
      {
       "cell_index": 57
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
